# –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ AI-–¢—Ä–µ–π–¥–µ—Ä–∞

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-11-27
**–ë–∞–∑–æ–≤–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** 65-70%
**–¶–µ–ª–µ–≤–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** 95%+

---

## üéØ –≠–¢–ê–ü 1: AI –ú–æ–¥–µ–ª–∏ MVP (2-3 –Ω–µ–¥–µ–ª–∏)

### 1.1 Triple-Barrier Labeling
**–°—Ä–æ–∫:** 3 –¥–Ω—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
**–§–∞–π–ª:** `src/models/labeling/triple_barrier.py`

#### –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è:
```python
def triple_barrier_labels(
    prices: pd.Series,
    *,
    profit_target: float,  # PT barrier (–≤ ATR –º–Ω–æ–∂–∏—Ç–µ–ª—è—Ö)
    stop_loss: float,      # SL barrier (–≤ ATR –º–Ω–æ–∂–∏—Ç–µ–ª—è—Ö)
    max_holding: int,      # –í—Ä–µ–º–µ–Ω–Ω–æ–π –±–∞—Ä—å–µ—Ä (–≤ –±–∞—Ä–∞—Ö)
    atr: pd.Series,        # ATR –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –±–∞—Ä—å–µ—Ä–æ–≤
) -> pd.DataFrame:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–µ—Ç–∫–∏ –ø–æ –º–µ—Ç–æ–¥—É Triple Barrier.

    Returns:
        DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
        - label: {-1, 0, 1}
        - barrier_hit: {'profit', 'stop', 'time'}
        - holding_period: int
        - return_pct: float
    """
```

#### –ê–ª–≥–æ—Ä–∏—Ç–º:
1. –î–ª—è –∫–∞–∂–¥–æ–π —Å–≤–µ—á–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å 3 –±–∞—Ä—å–µ—Ä–∞:
   - Upper: entry_price + (profit_target * ATR)
   - Lower: entry_price - (stop_loss * ATR)
   - Time: max_holding bars –≤–ø–µ—Ä–µ–¥
2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–æ–π –±–∞—Ä—å–µ—Ä –∫–æ—Å–Ω—É–ª—Å—è –ø–µ—Ä–≤—ã–º
3. –ü—Ä–∏—Å–≤–æ–∏—Ç—å –º–µ—Ç–∫—É:
   - +1: –∫–æ—Å–Ω—É–ª—Å—è Upper (profit)
   - -1: –∫–æ—Å–Ω—É–ª—Å—è Lower (stop loss)
   - 0: –∫–æ—Å–Ω—É–ª—Å—è Time (timeout)

#### –¢–µ—Å—Ç—ã:
- `tests/test_triple_barrier.py`:
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–∫
  - Edge cases (–≤—Å–µ 3 –±–∞—Ä—å–µ—Ä–∞ –Ω–∞ –æ–¥–Ω–æ–π —Å–≤–µ—á–µ)
  - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö

#### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```python
# requirements.txt
pandas>=1.5.0
numpy>=1.24.0
```

---

### 1.2 LSTM –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
**–°—Ä–æ–∫:** 5 –¥–Ω–µ–π
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
**–§–∞–π–ª:** `src/models/forecast/lstm_model.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
```python
class LSTMForecaster:
    """
    LSTM –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏—Ö N —Å–≤–µ—á–µ–π.

    Architecture:
        Input: [batch, sequence_length, features]
        LSTM1: 128 units, return_sequences=True, dropout=0.2
        LSTM2: 64 units, return_sequences=False, dropout=0.2
        Dense1: 32 units, ReLU
        Dense2: n_forecast units (close prices)

    Features (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):
        - close, high, low, open
        - volume
        - RSI, MACD, ATR
        - Returns (log)
    """

    def __init__(
        self,
        sequence_length: int = 60,    # 60 –±–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        n_forecast: int = 3,           # –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å 3 —Å–≤–µ—á–∏
        features: list[str] = None,
        lstm_units: tuple[int, int] = (128, 64),
        dropout: float = 0.2,
    ):
        ...

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        *,
        validation_split: float = 0.2,
        epochs: int = 100,
        batch_size: int = 32,
        early_stopping_patience: int = 10,
    ) -> dict:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å early stopping."""
        ...

    def predict(self, X: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö n_forecast —Å–≤–µ—á–µ–π."""
        ...

    def evaluate(self, X: np.ndarray, y: np.ndarray) -> dict:
        """
        –ú–µ—Ç—Ä–∏–∫–∏:
        - MSE, RMSE, MAE
        - Directional accuracy (–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è)
        - R¬≤ score
        """
        ...
```

#### –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:
```python
class LSTMDataPreprocessor:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM."""

    def __init__(self, scaler_type: str = "minmax"):
        """
        scaler_type: 'minmax', 'standard', 'robust'
        """
        ...

    def create_sequences(
        self,
        df: pd.DataFrame,
        sequence_length: int,
        n_forecast: int,
        features: list[str],
        target: str = "close",
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

        Returns:
            X: [n_samples, sequence_length, n_features]
            y: [n_samples, n_forecast]
        """
        ...

    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Fit scaler –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è."""
        ...

    def inverse_transform(self, predictions: np.ndarray) -> np.ndarray:
        """–û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π."""
        ...
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ModelRouter:
```python
# services/model_router.py

from src.models.forecast.lstm_model import LSTMForecaster

class ModelRouter:
    def __init__(self, config: ExecutionConfig):
        ...
        if config.forecast.name == "lstm":
            self.forecaster = LSTMForecaster.load(
                config.forecast.params.get("model_path")
            )
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
```yaml
# configs/exec.yaml

models:
  signal: "signal:rf_rule"
  sentiment: "sentiment:finbert"
  regime: "regime:kmeans"
  forecast: "forecast:lstm"  # –ù–û–í–û–ï

forecast:
  lstm:
    model_path: "models/lstm_v1.h5"
    sequence_length: 60
    n_forecast: 3
    features:
      - close
      - high
      - low
      - open
      - volume
      - rsi
      - macd
      - atr
```

#### –¢–µ—Å—Ç—ã:
- `tests/test_lstm_model.py`:
  - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
  - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ñ–æ—Ä–º—ã –≤—ã—Ö–æ–¥–∞
  - Directional accuracy > 55%
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ModelRouter

#### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```python
# requirements.txt (–æ–±–Ω–æ–≤–∏—Ç—å)
tensorflow>=2.13.0  # –∏–ª–∏ pytorch>=2.0.0
scikit-learn>=1.3.0
```

---

### 1.3 Purged Walk-Forward Cross-Validation
**–°—Ä–æ–∫:** 3 –¥–Ω—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
**–§–∞–π–ª:** `src/models/validation/purged_cv.py`

#### –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è:
```python
class PurgedWalkForwardCV:
    """
    Walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å purging –∏ embargo.

    –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç leakage –º–µ–∂–¥—É train/test:
    - Purging: —É–¥–∞–ª—è–µ—Ç overlapping samples
    - Embargo: gap –º–µ–∂–¥—É train –∏ test
    """

    def __init__(
        self,
        n_splits: int = 5,
        train_period: int = 252,  # ~1 –≥–æ–¥
        test_period: int = 63,    # ~3 –º–µ—Å—è—Ü–∞
        embargo_period: int = 21, # ~1 –º–µ—Å—è—Ü
        purge_pct: float = 0.01,  # 1% –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è —É–¥–∞–ª–∏—Ç—å
    ):
        ...

    def split(self, X: pd.DataFrame, y: pd.Series) -> Iterator[tuple]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä train/test –∏–Ω–¥–µ–∫—Å–æ–≤.

        Yields:
            (train_idx, test_idx) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ fold
        """
        ...

    def cross_val_score(
        self,
        model,
        X: pd.DataFrame,
        y: pd.Series,
        *,
        scoring: str = "accuracy",
    ) -> dict:
        """
        –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏.

        Returns:
            {
                'scores': [score1, score2, ...],
                'mean': float,
                'std': float,
                'sharpe': float,  # –µ—Å–ª–∏ scoring == 'returns'
                'max_dd': float,
            }
        """
        ...
```

#### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:
```python
def plot_cv_splits(cv: PurgedWalkForwardCV, X: pd.DataFrame):
    """
    –ì—Ä–∞—Ñ–∏–∫ train/test splits –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª–µ.

    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
    - Train periods (—Å–∏–Ω–∏–π)
    - Test periods (–∑–µ–ª–µ–Ω—ã–π)
    - Embargo gaps (–∫—Ä–∞—Å–Ω—ã–π)
    """
    ...
```

#### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
```python
from src.models.validation.purged_cv import PurgedWalkForwardCV
from src.models.signal.random_forest_rule import RandomForestSignal

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X = df[['rsi', 'macd', 'atr', 'volume']]
y = triple_barrier_labels(df['close'])

# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
cv = PurgedWalkForwardCV(
    n_splits=5,
    train_period=252,
    test_period=63,
    embargo_period=21,
)

model = RandomForestSignal()
results = cv.cross_val_score(model, X, y, scoring='accuracy')

print(f"Mean accuracy: {results['mean']:.3f} ¬± {results['std']:.3f}")
print(f"Sharpe ratio: {results['sharpe']:.2f}")
```

#### –¢–µ—Å—Ç—ã:
- `tests/test_purged_cv.py`:
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è overlaps
  - Embargo period —Å–æ–±–ª—é–¥–∞–µ—Ç—Å—è
  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ splits –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

---

### 1.4 –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
**–°—Ä–æ–∫:** 4 –¥–Ω—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
**–§–∞–π–ª:** `tasks/model_retraining.py`

#### –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è:
```python
class ModelRetrainingPipeline:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    Workflow:
    1. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
    2. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏ (triple-barrier)
    3. Walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è
    4. –û–±—É—á–∏—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
    5. –°—Ä–∞–≤–Ω–∏—Ç—å —Å —Ç–µ–∫—É—â–µ–π (A/B test)
    6. Deploy –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ
    7. Rollback –µ—Å–ª–∏ —Ö—É–∂–µ
    """

    def __init__(
        self,
        model_type: str,  # 'lstm', 'cnn', 'transformer'
        config_path: str,
        db_connection: str,
    ):
        ...

    async def run_retraining_cycle(self) -> dict:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.

        Returns:
            {
                'status': 'success' | 'failed' | 'rolled_back',
                'new_model_path': str,
                'metrics': {
                    'accuracy': float,
                    'sharpe': float,
                    'max_dd': float,
                },
                'comparison': {
                    'old_model': {...},
                    'new_model': {...},
                    'improvement_pct': float,
                },
            }
        """
        # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        df = await self._load_recent_data(days=365)

        # 2. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏
        labels = triple_barrier_labels(df['close'], ...)

        # 3. Walk-forward CV
        cv_results = self._validate_model(df, labels)

        # 4. –û–±—É—á–∏—Ç—å
        new_model = self._train_model(df, labels)

        # 5. A/B —Ç–µ—Å—Ç
        if self._is_better_than_current(new_model, cv_results):
            self._deploy_model(new_model)
            return {'status': 'success', ...}
        else:
            self._rollback()
            return {'status': 'rolled_back', ...}

    def _is_better_than_current(
        self,
        new_model,
        cv_results: dict,
        *,
        min_improvement_pct: float = 5.0,
    ) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.

        –ö—Ä–∏—Ç–µ—Ä–∏–∏:
        - Sharpe ratio >= +5%
        - Max drawdown <= -5%
        - Directional accuracy >= +2%
        """
        ...

    def _deploy_model(self, model, version: str):
        """
        Deploy –º–æ–¥–µ–ª–∏:
        1. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ models/{type}_v{version}.h5
        2. –û–±–Ω–æ–≤–∏—Ç—å configs/exec.yaml
        3. –°–æ–∑–¥–∞—Ç—å git commit
        4. –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram
        """
        ...

    def _rollback(self):
        """–û—Ç–∫–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏."""
        ...
```

#### Scheduler (Celery/APScheduler):
```python
# tasks/scheduler.py

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from tasks.model_retraining import ModelRetrainingPipeline

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('cron', day_of_week='sun', hour=2)
async def weekly_lstm_retraining():
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ LSTM –∫–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 2:00."""
    pipeline = ModelRetrainingPipeline(
        model_type='lstm',
        config_path='configs/exec.yaml',
        db_connection=settings.DATABASE_URL,
    )

    result = await pipeline.run_retraining_cycle()

    # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç –≤ Telegram
    await telegram_bot.send_message(
        f"LSTM Retraining: {result['status']}\n"
        f"New Sharpe: {result['metrics']['sharpe']:.2f}\n"
        f"Improvement: {result['comparison']['improvement_pct']:.1f}%"
    )

scheduler.start()
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ main.py:
```python
# src/main.py

@app.on_event("startup")
async def startup_tasks():
    ...

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å scheduler –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    if settings.MODEL_RETRAINING_ENABLED:
        from tasks.scheduler import scheduler
        scheduler.start()
        logger.info("Model retraining scheduler started")
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
```yaml
# configs/exec.yaml

model_retraining:
  enabled: true
  schedule:
    lstm: "weekly"      # –∫–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
    cnn: "biweekly"     # –∫–∞–∂–¥—ã–µ 2 –Ω–µ–¥–µ–ª–∏
    transformer: "monthly"
  min_improvement_pct: 5.0
  max_models_to_keep: 5  # –∏—Å—Ç–æ—Ä–∏—è –≤–µ—Ä—Å–∏–π
  notification:
    telegram: true
    email: false
```

#### –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:
```
models/
‚îú‚îÄ‚îÄ lstm_v1.h5        (2025-01-15, sharpe=1.2)
‚îú‚îÄ‚îÄ lstm_v2.h5        (2025-01-22, sharpe=1.35)
‚îú‚îÄ‚îÄ lstm_v3.h5        (2025-01-29, sharpe=1.28) ‚Üê rollback
‚îú‚îÄ‚îÄ lstm_current.h5 -> lstm_v2.h5  (symlink –∫ best)
‚îî‚îÄ‚îÄ metadata.json
```

#### –¢–µ—Å—Ç—ã:
- `tests/test_model_retraining.py`:
  - Mock –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
  - A/B comparison logic
  - Rollback –º–µ—Ö–∞–Ω–∏–∑–º
  - –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

#### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```python
# requirements.txt
apscheduler>=3.10.0  # –∏–ª–∏ celery>=5.3.0
mlflow>=2.8.0        # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è tracking
```

---

## üéØ –≠–¢–ê–ü 2: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (1 –Ω–µ–¥–µ–ª—è)

### 2.1 Telegram-–±–æ—Ç
**–°—Ä–æ–∫:** 5 –¥–Ω–µ–π
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –í—ã—Å–æ–∫–∏–π
**–§–∞–π–ª:** `services/telegram_bot.py`

#### –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è:
```python
class TradingTelegramBot:
    """
    Telegram –±–æ—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–π–¥–µ—Ä–æ–º.

    –ö–æ–º–∞–Ω–¥—ã:
    - /start - –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –ø–æ–º–æ—â—å
    - /status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    - /pnl - —Ç–µ–∫—É—â–∏–π PnL
    - /positions - –æ—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏
    - /trades - –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏
    - /stop - —ç–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
    - /resume - –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ—Ä–≥–æ–≤–ª—é
    - /limits - –¥–Ω–µ–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã
    - /config - —Ç–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

    –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è:
    - –ù–æ–≤—ã–µ —Å–¥–µ–ª–∫–∏ (–æ—Ç–∫—Ä—ã—Ç–∏–µ/–∑–∞–∫—Ä—ã—Ç–∏–µ)
    - –û—à–∏–±–∫–∏ –∏ –∞–ª–µ—Ä—Ç—ã
    - –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤
    - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    - –î–Ω–µ–≤–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
    """

    def __init__(
        self,
        bot_token: str,
        allowed_users: list[int],  # Telegram user IDs
        trading_service: TradingService,
    ):
        ...

    async def start(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞."""
        self.app = Application.builder().token(self.bot_token).build()

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è handlers
        self.app.add_handler(CommandHandler("start", self.cmd_start))
        self.app.add_handler(CommandHandler("status", self.cmd_status))
        self.app.add_handler(CommandHandler("pnl", self.cmd_pnl))
        self.app.add_handler(CommandHandler("positions", self.cmd_positions))
        self.app.add_handler(CommandHandler("stop", self.cmd_emergency_stop))

        # Inline –∫–Ω–æ–ø–∫–∏ –¥–ª—è emergency stop
        self.app.add_handler(CallbackQueryHandler(self.btn_confirm_stop))

        await self.app.run_polling()

    async def cmd_status(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        –ö–æ–º–∞–Ω–¥–∞ /status

        –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
        - –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã (running/stopped)
        - –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∏—Ä–∂–µ–π
        - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
        - –¢–µ–∫—É—â–∏–π equity
        - –î–Ω–µ–≤–Ω–æ–π PnL
        """
        status = await self.trading_service.get_status()

        message = f"""
ü§ñ **AI Trader Status**

System: {'üü¢ Running' if status.running else 'üî¥ Stopped'}
Broker: {'üü¢ Connected' if status.broker_connected else 'üî¥ Disconnected'}

üíº Positions: {status.open_positions}
üí∞ Equity: ${status.equity:,.2f}
üìä Day PnL: ${status.day_pnl:+,.2f} ({status.day_pnl_pct:+.2f}%)

‚ö†Ô∏è Day Trades: {status.day_trades}/{status.max_day_trades}
üõë Day Loss Limit: ${status.day_loss_limit:,.2f}
        """

        await update.message.reply_text(message, parse_mode='Markdown')

    async def cmd_emergency_stop(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        –ö–æ–º–∞–Ω–¥–∞ /stop —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º

        –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç inline –∫–Ω–æ–ø–∫–∏:
        - ‚úÖ Confirm Stop
        - ‚ùå Cancel
        """
        keyboard = [
            [
                InlineKeyboardButton("‚úÖ Confirm STOP", callback_data="stop_confirmed"),
                InlineKeyboardButton("‚ùå Cancel", callback_data="stop_cancelled"),
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await update.message.reply_text(
            "‚ö†Ô∏è **EMERGENCY STOP**\n\n"
            "This will:\n"
            "- Close all positions at market price\n"
            "- Cancel all pending orders\n"
            "- Pause trading\n\n"
            "Confirm?",
            reply_markup=reply_markup,
            parse_mode='Markdown',
        )

    async def btn_confirm_stop(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è."""
        query = update.callback_query
        await query.answer()

        if query.data == "stop_confirmed":
            result = await self.trading_service.emergency_stop()

            await query.edit_message_text(
                f"üõë **EMERGENCY STOP EXECUTED**\n\n"
                f"Closed positions: {result.closed_positions}\n"
                f"Cancelled orders: {result.cancelled_orders}\n"
                f"Final PnL: ${result.final_pnl:+,.2f}"
            )
        else:
            await query.edit_message_text("‚ùå Emergency stop cancelled")

    async def send_trade_notification(self, trade: Trade):
        """
        –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–π —Å–¥–µ–ª–∫–µ.

        –§–æ—Ä–º–∞—Ç:
        üìà LONG BTC/USDT OPENED
        Entry: $45,123.45
        Size: 0.05 BTC ($2,256)
        SL: $44,000 | TP: $47,000
        Confidence: 78%
        """
        direction = "üìà LONG" if trade.side == "buy" else "üìâ SHORT"
        action = "OPENED" if trade.action == "open" else "CLOSED"

        message = f"""
{direction} {trade.symbol} {action}

{'Entry' if trade.action == 'open' else 'Exit'}: ${trade.price:,.2f}
Size: {trade.quantity:.4f} ({trade.notional:,.0f} USDT)
"""

        if trade.action == "open":
            message += f"""
SL: ${trade.stop_loss:,.2f} | TP: ${trade.take_profit:,.2f}
Confidence: {trade.confidence:.0f}%
Reason: {trade.reason}
"""
        else:
            message += f"""
PnL: ${trade.pnl:+,.2f} ({trade.pnl_pct:+.2f}%)
Duration: {trade.duration}
Reason: {trade.close_reason}
"""

        await self.send_to_all_users(message)

    async def send_daily_report(self):
        """
        –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç (–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ 00:00 UTC).

        –§–æ—Ä–º–∞—Ç:
        üìä Daily Report - 2025-01-27

        Trades: 12
        Win rate: 58.3% (7W/5L)
        PnL: +$1,234.56 (+1.23%)
        Best trade: +$456.78 (BTC/USDT LONG)
        Worst trade: -$123.45 (ETH/USDT SHORT)

        Sharpe: 1.85
        Max DD: -2.3%
        """
        report = await self.trading_service.get_daily_report()

        message = f"""
üìä **Daily Report** - {report.date}

üìà Trades: {report.total_trades}
‚úÖ Win rate: {report.win_rate:.1f}% ({report.wins}W/{report.losses}L)
üí∞ PnL: ${report.pnl:+,.2f} ({report.pnl_pct:+.2f}%)

üèÜ Best: +${report.best_trade:,.2f} ({report.best_symbol})
üíî Worst: ${report.worst_trade:+,.2f} ({report.worst_symbol})

üìä Sharpe: {report.sharpe:.2f}
üìâ Max DD: {report.max_dd:.2f}%
        """

        await self.send_to_all_users(message, parse_mode='Markdown')

    async def send_to_all_users(self, message: str, **kwargs):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º."""
        for user_id in self.allowed_users:
            try:
                await self.app.bot.send_message(user_id, message, **kwargs)
            except Exception as e:
                logger.error(f"Failed to send message to {user_id}: {e}")
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ main.py:
```python
# src/main.py

telegram_bot: Optional[TradingTelegramBot] = None

@app.on_event("startup")
async def startup_telegram():
    global telegram_bot

    if settings.TELEGRAM_BOT_ENABLED:
        telegram_bot = TradingTelegramBot(
            bot_token=settings.TELEGRAM_BOT_TOKEN,
            allowed_users=settings.TELEGRAM_ALLOWED_USERS,
            trading_service=trading_service,
        )

        asyncio.create_task(telegram_bot.start())
        logger.info("Telegram bot started")
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
```yaml
# configs/exec.yaml

telegram:
  enabled: true
  bot_token_env: TELEGRAM_BOT_TOKEN
  allowed_users:
    - 123456789  # –í–∞—à Telegram user ID
  notifications:
    trades: true
    errors: true
    daily_report: true
    daily_report_time: "00:00"  # UTC
    retraining_results: true
  rate_limit:
    max_messages_per_minute: 10
```

#### Environment variables:
```bash
# .env
TELEGRAM_BOT_TOKEN=123456:ABC-DEF...
TELEGRAM_ALLOWED_USERS=123456789,987654321
```

#### –¢–µ—Å—Ç—ã:
- `tests/test_telegram_bot.py`:
  - Mock –∫–æ–º–∞–Ω–¥—ã
  - Emergency stop workflow
  - –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
  - Rate limiting

#### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```python
# requirements.txt
python-telegram-bot>=20.7
```

---

### 2.2 Auto-restart –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
**–°—Ä–æ–∫:** 2 –¥–Ω—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –í—ã—Å–æ–∫–∏–π

#### 2.2.1 Systemd service
**–§–∞–π–ª:** `deploy/systemd/ai-trader.service`

```ini
[Unit]
Description=AI Trading Bot
After=network.target postgresql.service
Wants=postgresql.service

[Service]
Type=simple
User=aitrader
Group=aitrader
WorkingDirectory=/opt/ai_trader

# Environment
EnvironmentFile=/opt/ai_trader/.env

# Start command
ExecStart=/opt/ai_trader/venv/bin/python -m uvicorn src.main:app --host 0.0.0.0 --port 8000

# Restart policy
Restart=always
RestartSec=10
StartLimitIntervalSec=0

# Health check (—Ç—Ä–µ–±—É–µ—Ç systemd >=248)
# –ï—Å–ª–∏ /health –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ 200, restart
ExecStartPost=/bin/bash -c 'sleep 5 && curl -f http://localhost:8000/health || exit 1'

# Graceful shutdown
TimeoutStopSec=30
KillMode=mixed
KillSignal=SIGTERM

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=ai-trader

# Security
NoNewPrivileges=true
PrivateTmp=true

# Resource limits
LimitNOFILE=65536
LimitNPROC=4096

[Install]
WantedBy=multi-user.target
```

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞:
```bash
# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å service file
sudo cp deploy/systemd/ai-trader.service /etc/systemd/system/

# Reload systemd
sudo systemctl daemon-reload

# –í–∫–ª—é—á–∏—Ç—å auto-start
sudo systemctl enable ai-trader

# –ó–∞–ø—É—Å—Ç–∏—Ç—å
sudo systemctl start ai-trader

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å
sudo systemctl status ai-trader

# –õ–æ–≥–∏
sudo journalctl -u ai-trader -f
```

---

#### 2.2.2 Docker restart policies
**–§–∞–π–ª:** `docker-compose.yml` (–æ–±–Ω–æ–≤–∏—Ç—å)

```yaml
version: '3.8'

services:
  app:
    build: .
    container_name: ai_trader_app
    restart: unless-stopped  # –ù–û–í–û–ï: auto-restart
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/aitrader
      - BINANCE_API_KEY=${BINANCE_API_KEY}
      - BINANCE_API_SECRET=${BINANCE_API_SECRET}
    depends_on:
      db:
        condition: service_healthy
    healthcheck:  # –ù–û–í–û–ï: health check
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:  # –ù–û–í–û–ï: resource limits
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  db:
    image: postgres:15-alpine
    container_name: ai_trader_db
    restart: unless-stopped  # –ù–û–í–û–ï
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: aitrader
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:  # –ù–û–í–û–ï
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  prometheus:  # –ù–û–í–û–ï: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    image: prom/prometheus:latest
    container_name: ai_trader_prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'

volumes:
  postgres_data:
  prometheus_data:
```

#### Healthcheck endpoint enhancement:
```python
# routers/health.py (–æ–±–Ω–æ–≤–∏—Ç—å)

@router.get("/health")
async def health_check(db: AsyncSession = Depends(get_db)):
    """
    Enhanced health check.

    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    - Database connection
    - Broker connection
    - Disk space
    - Memory usage
    """
    checks = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {},
    }

    # DB check
    try:
        await db.execute(text("SELECT 1"))
        checks["checks"]["database"] = "ok"
    except Exception as e:
        checks["status"] = "unhealthy"
        checks["checks"]["database"] = f"error: {e}"

    # Broker check
    try:
        broker_status = await broker_gateway.ping()
        checks["checks"]["broker"] = "ok" if broker_status else "error"
    except Exception as e:
        checks["status"] = "unhealthy"
        checks["checks"]["broker"] = f"error: {e}"

    # Disk space check (>10% free)
    disk_usage = shutil.disk_usage("/")
    free_pct = (disk_usage.free / disk_usage.total) * 100
    if free_pct < 10:
        checks["status"] = "degraded"
        checks["checks"]["disk"] = f"low: {free_pct:.1f}% free"
    else:
        checks["checks"]["disk"] = f"ok: {free_pct:.1f}% free"

    # Memory check (>20% free)
    mem = psutil.virtual_memory()
    if mem.available / mem.total < 0.2:
        checks["status"] = "degraded"
        checks["checks"]["memory"] = f"low: {mem.percent}% used"
    else:
        checks["checks"]["memory"] = f"ok: {mem.percent}% used"

    status_code = 200 if checks["status"] == "healthy" else 503
    return JSONResponse(content=checks, status_code=status_code)
```

---

#### –¢–µ—Å—Ç—ã auto-restart:
```bash
# –¢–µ—Å—Ç 1: Kill –ø—Ä–æ—Ü–µ—Å—Å
sudo systemctl stop ai-trader
# –î–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ 10 —Å–µ–∫
sleep 15
sudo systemctl status ai-trader  # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å active

# –¢–µ—Å—Ç 2: Simulate crash
docker exec ai_trader_app kill -9 1
# Docker –¥–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
sleep 10
docker ps  # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å running

# –¢–µ—Å—Ç 3: Health check failure
# –í—Ä–µ–º–µ–Ω–Ω–æ —Å–ª–æ–º–∞—Ç—å /health endpoint
# Docker –¥–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ 3 failed checks (90 —Å–µ–∫)
```

---

## üéØ –≠–¢–ê–ü 3: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ AI –º–æ–¥–µ–ª–∏ (4-6 –Ω–µ–¥–µ–ª—å)

### 3.1 CNN –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
**–°—Ä–æ–∫:** 1-2 –Ω–µ–¥–µ–ª–∏
**–§–∞–π–ª:** `src/models/signal/cnn_pattern.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
```python
class CNNPatternDetector:
    """
    CNN –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.

    Architecture:
        Input: [batch, height=50, width=50, channels=4]  # OHLC as image

        Conv2D1: 32 filters, 3x3, ReLU
        MaxPooling2D: 2x2
        Conv2D2: 64 filters, 3x3, ReLU
        MaxPooling2D: 2x2
        Conv2D3: 128 filters, 3x3, ReLU
        GlobalAveragePooling2D

        Dense1: 256 units, ReLU, Dropout(0.5)
        Dense2: 128 units, ReLU
        Output: 3 units, Softmax (BUY/SELL/HOLD)

    Patterns to detect:
        - Head and Shoulders
        - Double Top/Bottom
        - Triangle (ascending/descending/symmetric)
        - Wedge (rising/falling)
        - Flag, Pennant
        - Cup and Handle
    """

    def ohlc_to_image(
        self,
        df: pd.DataFrame,
        window: int = 50,
        img_size: tuple[int, int] = (50, 50),
    ) -> np.ndarray:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OHLC –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.

        –ú–µ—Ç–æ–¥:
        1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–Ω –≤ [0, 1]
        2. –°–æ–∑–¥–∞–Ω–∏–µ candlestick –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        3. Resize –¥–æ img_size

        Returns:
            [height, width, 4]  # RGBA
        """
        ...
```

*(–î–µ—Ç–∞–ª–∏ –æ–ø—É—â–µ–Ω—ã –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ - —Å–º. –æ—Ç–¥–µ–ª—å–Ω–æ–µ –¢–ó)*

---

### 3.2 Transformer
**–°—Ä–æ–∫:** 2-3 –Ω–µ–¥–µ–ª–∏
**–§–∞–π–ª:** `src/models/signal/transformer_signal.py`

*(–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±—É–¥–µ—Ç –æ–ø–∏—Å–∞–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –¢–ó)*

---

### 3.3 DRL Agent (PPO)
**–°—Ä–æ–∫:** 2-3 –Ω–µ–¥–µ–ª–∏
**–§–∞–π–ª:** `src/models/drl/ppo_agent.py`

*(–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±—É–¥–µ—Ç –æ–ø–∏—Å–∞–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –¢–ó)*

---

## üéØ –≠–¢–ê–ü 4: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (2-3 –Ω–µ–¥–µ–ª–∏)

### 4.1 Twitter/X Integration
**–°—Ä–æ–∫:** 1 –Ω–µ–¥–µ–ª—è
**–§–∞–π–ª:** `news/twitter_client.py`

*(–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –±—É–¥–µ—Ç –æ–ø–∏—Å–∞–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –¢–ó)*

---

### 4.2 Fear & Greed Index
**–°—Ä–æ–∫:** 2 –¥–Ω—è
**–§–∞–π–ª:** `sources/fear_greed.py`

```python
class FearGreedIndexClient:
    """
    Crypto Fear & Greed Index from alternative.me

    API: https://api.alternative.me/fng/

    Values:
    - 0-24: Extreme Fear
    - 25-49: Fear
    - 50-74: Greed
    - 75-100: Extreme Greed
    """

    async def get_current(self) -> dict:
        """
        –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞.

        Returns:
            {
                'value': 45,
                'classification': 'Fear',
                'timestamp': '2025-01-27T12:00:00Z',
            }
        """
        ...

    async def get_historical(self, days: int = 30) -> pd.DataFrame:
        """–ò—Å—Ç–æ—Ä–∏—è –∑–∞ N –¥–Ω–µ–π."""
        ...
```

---

### 4.3 –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å
**–°—Ä–æ–∫:** 1 –Ω–µ–¥–µ–ª—è
**–§–∞–π–ª:** `sources/economic_calendar.py`

*(–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –±—É–¥–µ—Ç –æ–ø–∏—Å–∞–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –¢–ó)*

---

## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ç—Ä—É–¥–æ–∑–∞—Ç—Ä–∞—Ç

| –≠—Ç–∞–ø | –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –°—Ä–æ–∫ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|------|-----------|------|-----------|
| **1** | Triple-Barrier Labeling | 3 –¥–Ω—è | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| **1** | LSTM –º–æ–¥–µ–ª—å | 5 –¥–Ω–µ–π | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| **1** | Purged Walk-Forward CV | 3 –¥–Ω—è | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| **1** | –ê–≤—Ç–æ–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | 4 –¥–Ω–µ–π | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| | **–ò–¢–û–ì–û –≠–¢–ê–ü 1** | **2-3 –Ω–µ–¥–µ–ª–∏** | |
| **2** | Telegram-–±–æ—Ç | 5 –¥–Ω–µ–π | üü° –í—ã—Å–æ–∫–∏–π |
| **2** | Auto-restart | 2 –¥–Ω—è | üü° –í—ã—Å–æ–∫–∏–π |
| | **–ò–¢–û–ì–û –≠–¢–ê–ü 2** | **1 –Ω–µ–¥–µ–ª—è** | |
| **3** | CNN –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ | 1-2 –Ω–µ–¥–µ–ª–∏ | üü¢ –°—Ä–µ–¥–Ω–∏–π |
| **3** | Transformer | 2-3 –Ω–µ–¥–µ–ª–∏ | üü¢ –°—Ä–µ–¥–Ω–∏–π |
| **3** | DRL Agent | 2-3 –Ω–µ–¥–µ–ª–∏ | üü¢ –°—Ä–µ–¥–Ω–∏–π |
| | **–ò–¢–û–ì–û –≠–¢–ê–ü 3** | **4-6 –Ω–µ–¥–µ–ª—å** | |
| **4** | Twitter/X | 1 –Ω–µ–¥–µ–ª—è | üü¢ –°—Ä–µ–¥–Ω–∏–π |
| **4** | Fear & Greed | 2 –¥–Ω—è | üü¢ –ù–∏–∑–∫–∏–π |
| **4** | –≠–∫–æ–Ω–æ–º. –∫–∞–ª–µ–Ω–¥–∞—Ä—å | 1 –Ω–µ–¥–µ–ª—è | üü¢ –°—Ä–µ–¥–Ω–∏–π |
| | **–ò–¢–û–ì–û –≠–¢–ê–ü 4** | **2-3 –Ω–µ–¥–µ–ª–∏** | |
| | **–û–ë–©–ò–ô –°–†–û–ö** | **8-12 –Ω–µ–¥–µ–ª—å** | |

---

## üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

### –í–∞—Ä–∏–∞–Ω—Ç 1: MVP (80% –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∑–∞ 4 –Ω–µ–¥–µ–ª–∏)
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **–≠–¢–ê–ü 1 + –≠–¢–ê–ü 2**

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ LSTM –º–æ–¥–µ–ª—å —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
- ‚úÖ Triple-barrier labels
- ‚úÖ Purged CV –≤–∞–ª–∏–¥–∞—Ü–∏—è
- ‚úÖ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
- ‚úÖ Auto-restart
- **–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: ~80%**
- **–ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å production 24/7**

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ–ª–Ω–æ–µ –¢–ó (95% –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∑–∞ 12 –Ω–µ–¥–µ–ª—å)
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **–í–°–ï 4 –≠–¢–ê–ü–ê**

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ –í—Å–µ AI –º–æ–¥–µ–ª–∏ (LSTM, CNN, Transformer, DRL)
- ‚úÖ –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ 100% –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å
- **–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: ~95%**

---

## üìù –°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è

**–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:**

1. **–ù–∞—á–∞—Ç—å –≠–¢–ê–ü 1** (Triple-Barrier + LSTM + CV + –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)
2. **–ù–∞—á–∞—Ç—å –≠–¢–ê–ü 2** (Telegram + Auto-restart)
3. **–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é** –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
4. **–î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–ó** –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞

---

**–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:** Claude Code Agent
**–î–∞—Ç–∞:** 2025-11-27
**–í–µ—Ä—Å–∏—è:** 1.0
