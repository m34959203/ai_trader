# ML-Ops Runbook

Этот документ описывает регламент действий по обслуживанию моделей в платформе «AI-Trader».
Цель — обеспечить воспроизводимость обучения, контроль качества и своевременную реакцию на дрейф.

## 1. Подготовка окружения
- Активировать Python-окружение проекта и убедиться, что установлены зависимости из `requirements.txt` и `requirements-dev.txt`.
- Проверить наличие доступа к MLflow (если используется удалённый сервер) и авторизацию в Weights & Biases (`wandb login`).
- Убедиться, что переменная `AI_TRADER_MODEL_CACHE` указывает на директорию с достаточным объёмом для хранения моделей.

## 2. Обновление FinBERT
1. Запустить сервис или отдельный скрипт, который инициализирует `FinBERTLite`. При первом запуске модель автоматически выгрузится в `state/models/ProsusAI__finbert` (или в директорию из `AI_TRADER_MODEL_CACHE`).
2. Проверить логи на наличие строки `FinBERT snapshot ready` и записанный SHA-256 checksum.
3. Для принудительного обновления удалить кеш-директорию и перезапустить сервис.
4. В офлайн-режиме убедиться, что checksum совпадает и пайплайн запустился из локального кеша.

## 3. Переобучение meta-label модели
1. Подготовить датасет событий (CSV/Parquet) с колонками признаков и бинарным столбцом меток (по умолчанию `meta_label`).
2. Выполнить CLI:
   ```bash
   python scripts/meta_label_cli.py data/events.parquet \
       --model rf \
       --cv-folds 5 \
       --purge-gap 10 \
       --label-column meta_label \
       --time-column event_end \
       --output artifacts/meta_model.pkl \
       --mlflow-uri http://mlflow:5000 \
       --wandb-project ai-trader-meta
   ```
3. По завершении убедиться, что:
   - создан артефакт `meta_model.pkl` с моделью, списком признаков и метриками;
   - сохранён JSON-отчёт с агрегацией метрик CV;
   - в MLflow и/или W&B появился новый запуск с параметрами и метриками.
4. При необходимости загрузить модель в прод-окружение и обновить конфигурацию сервиса.

## 4. Наблюдение за дрейфом
- Дрейф-детекторы ADWIN активируются в рантайме через `ModelRouter`.
- Отчёты формируются в `state/drift_reports/*.json` при появлении предупреждений или факта дрейфа.
- При срабатывании дрейфа выполнить следующие шаги:
  1. Проанализировать отчёт (источник, сигнал, confidence).
  2. Проверить соответствующие метрики модели и свежесть данных.
  3. Если дрейф подтверждён — инициировать переобучение (см. раздел 3) и обновление моделей.
  4. Зафиксировать действия в системе тикетов/журналах.

## 5. Контроль качества и аудит
- Хранить все артефакты обучения в версионированном хранилище (например, S3/MinIO) с ссылкой на commit.
- Для каждого релиза моделей оформлять changelog с указанием датасета, параметров и целевых метрик.
- Еженедельно проверять доступность MLflow/W&B и целостность кеша моделей.

## 6. Экстренные сценарии
- **Ошибка загрузки модели:** переключить конфигурацию на rule-based fallback, починить кеш и повторно прогреть модель.
- **Отказ MLflow/W&B:** временно продолжать обучение локально, сохраняя JSON-отчёты; после восстановления сервиса догрузить исторические данные вручную.
- **Массовый дрейф:** перевести сервис в защитный режим (уменьшить лимиты риска), собрать оперативное совещание и при необходимости вернуться на стабильную версию модели.

Документ актуализируется по мере изменения процессов и инструментов ML-Ops.
